{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "ya55OdHVeLtj"
      },
      "outputs": [],
      "source": [
        "# Import the Abstract Base Class and abstractmethod\n",
        "from abc import ABC, abstractmethod"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define an abstract base class for runnable objects\n",
        "class Runnable(ABC):\n",
        "\n",
        "  # Abstract method that subclasses must implement\n",
        "  @abstractmethod\n",
        "  def invoke(input_data):\n",
        "    pass"
      ],
      "metadata": {
        "id": "Sjo6s0y5eZem"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fake LLM Class for demonstration purposes\n",
        "import random\n",
        "class FakeLLM(Runnable):\n",
        "  def __init__(self):\n",
        "    print(\"LLM Created\")\n",
        "\n",
        "  # Invoke method returns a random response from a predefined list\n",
        "  def invoke(self, prompt):\n",
        "    response_list = [\n",
        "        'Dhaka is the capital of Bangladesh',\n",
        "        'Knows about a lot',\n",
        "        'AI stands for Artificial Intelligence'\n",
        "    ]\n",
        "\n",
        "    return {'response': random.choice(response_list)}\n",
        "\n",
        "  # Predict method (similar to invoke for this fake class)\n",
        "  def predict(self, promts):\n",
        "    response_list = [\n",
        "        'Dhaka is the capital of Bangladesh',\n",
        "        'Knows about a lot',\n",
        "        'AI stands for Artificial Intelligence'\n",
        "    ]\n",
        "    return {\"response\" : random.choice(response_list)}"
      ],
      "metadata": {
        "id": "ucdAn4J3ebrQ"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fake Prompt Template Class\n",
        "class FakePromptTemplate(Runnable):\n",
        "\n",
        "  def __init__(self, template, input_variables):\n",
        "    self.template = template\n",
        "    self.input_variables = input_variables\n",
        "\n",
        "  # Invoke method formats the template with input data\n",
        "  def invoke(self, input_dict):\n",
        "    return self.template.format(**input_dict)\n",
        "\n",
        "  # Format method (same as invoke for this fake class)\n",
        "  def format(self, input_dict):\n",
        "    return self.template.format(**input_dict)"
      ],
      "metadata": {
        "id": "t3jjXef4euGu"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fake String Output Parser Class\n",
        "class FakeStrOutputParser(Runnable):\n",
        "\n",
        "  def __init__(self):\n",
        "    pass\n",
        "\n",
        "  # Invoke method extracts the 'response' from the input data\n",
        "  def invoke(self, input_data):\n",
        "    return input_data['response']"
      ],
      "metadata": {
        "id": "7_0paknAe04u"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Runnable Connector Class to chain runnables\n",
        "class RunnableConnector(Runnable):\n",
        "\n",
        "  def __init__(self, runnable_list):\n",
        "    self.runnable_list = runnable_list\n",
        "\n",
        "  # Invoke method runs the runnables in sequence\n",
        "  def invoke(self, input_data):\n",
        "\n",
        "    for runnable in self.runnable_list:\n",
        "      input_data = runnable.invoke(input_data)\n",
        "\n",
        "    return input_data"
      ],
      "metadata": {
        "id": "12WYi9Jle5g7"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a FakePromptTemplate instance\n",
        "template = FakePromptTemplate(\n",
        "    template='Write a {length} poem about {topic}',\n",
        "    input_variables=['length', 'topic']\n",
        ")"
      ],
      "metadata": {
        "id": "gO2n5fene_JF"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a FakeLLM instance\n",
        "llm = FakeLLM()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3h6XSxHsfDEk",
        "outputId": "86a78068-5d5e-49b7-cdac-edbe6f15d4bf"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LLM Created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a FakeStrOutputParser instance\n",
        "parser = FakeStrOutputParser()"
      ],
      "metadata": {
        "id": "Jep_70kifGu8"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a RunnableConnector chain\n",
        "chain = RunnableConnector([template, llm, parser])"
      ],
      "metadata": {
        "id": "GV4KJt2BfRPs"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Invoke the chain with specific inputs\n",
        "chain.invoke({'length':'long', 'topic':'bangladesh'})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "QvNMgvnDflC1",
        "outputId": "e4438011-070a-4b4c-b25b-a9dcce16290e"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'AI stands for Artificial Intelligence'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create another FakePromptTemplate instance\n",
        "template1 = FakePromptTemplate(\n",
        "    template='Write a joke about {topic}',\n",
        "    input_variables=['topic']\n",
        ")"
      ],
      "metadata": {
        "id": "KVcLaX5Zfp18"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a third FakePromptTemplate instance\n",
        "template2 = FakePromptTemplate(\n",
        "    template='Explain the following joke {response}',\n",
        "    input_variables=['response']\n",
        ")"
      ],
      "metadata": {
        "id": "lI64mUyrfzL8"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a RunnableConnector chain1\n",
        "chain1 = RunnableConnector([template1, llm])"
      ],
      "metadata": {
        "id": "-VyoXg9Zf364"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a RunnableConnector chain2\n",
        "chain2 = RunnableConnector([template2, llm, parser])"
      ],
      "metadata": {
        "id": "mpsRfcXYf7rU"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a final chain by combining chain1 and chain2\n",
        "final_chain = RunnableConnector([chain1, chain2])"
      ],
      "metadata": {
        "id": "Y8LWO1a9f_4a"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_chain.invoke({'topic':'cricket'})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Ynk9MCJRgAxq",
        "outputId": "e274ab5c-10d2-4237-ccdf-17cce8a735e5"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Knows about a lot'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    }
  ]
}